<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LSTM Sentiment Analysis - Complete Explanation</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.8;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #4a5568;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        
        h2 {
            color: #2d3748;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            margin-top: 40px;
            font-size: 1.8em;
        }
        
        h3 {
            color: #4a5568;
            margin-top: 30px;
            font-size: 1.4em;
            border-left: 4px solid #667eea;
            padding-left: 15px;
        }
        
        .concept-box {
            background: linear-gradient(135deg, #e6fffa 0%, #b2f5ea 100%);
            border: 1px solid #81e6d9;
            border-radius: 12px;
            padding: 25px;
            margin: 20px 0;
            border-left: 6px solid #38b2ac;
        }
        
        .analogy {
            background: linear-gradient(135deg, #fef5e7 0%, #fbd38d 100%);
            border: 1px solid #ecc94b;
            border-radius: 12px;
            padding: 25px;
            margin: 20px 0;
            border-left: 6px solid #d69e2e;
        }
        
        .code-section {
            background: #1a202c;
            color: #68d391;
            padding: 20px;
            border-radius: 12px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            margin: 15px 0;
            border: 1px solid #4a5568;
            position: relative;
        }
        
        .code-title {
            background: #2d3748;
            color: #e2e8f0;
            padding: 8px 15px;
            margin: -20px -20px 15px -20px;
            border-radius: 12px 12px 0 0;
            font-weight: bold;
            font-size: 0.9em;
        }
        
        .step {
            background: #f7fafc;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
            counter-increment: step-counter;
        }
        
        .step::before {
            content: "Step " counter(step-counter) ": ";
            font-weight: bold;
            color: #667eea;
            font-size: 1.1em;
        }
        
        body {
            counter-reset: step-counter;
        }
        
        .warning {
            background: #fed7d7;
            border: 1px solid #fc8181;
            color: #742a2a;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .success {
            background: #c6f6d5;
            border: 1px solid #68d391;
            color: #22543d;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .info {
            background: #bee3f8;
            border: 1px solid #63b3ed;
            color: #2c5282;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .flow-diagram {
            background: #f7fafc;
            border: 2px solid #e2e8f0;
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
            text-align: center;
            font-family: monospace;
        }
        
        .arrow {
            color: #667eea;
            font-size: 1.5em;
            margin: 10px 0;
        }
        
        .highlight {
            background: #fed7fe;
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: bold;
        }
        
        .lstm-visual {
            background: linear-gradient(135deg, #e6fffa 0%, #b2f5ea 100%);
            border: 2px solid #38b2ac;
            border-radius: 15px;
            padding: 25px;
            margin: 25px 0;
            text-align: center;
        }
        
        .neural-node {
            display: inline-block;
            width: 60px;
            height: 60px;
            background: #667eea;
            border-radius: 50%;
            color: white;
            line-height: 60px;
            margin: 10px;
            font-weight: bold;
        }
        
        .data-flow {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .data-box {
            background: #667eea;
            color: white;
            padding: 10px 15px;
            border-radius: 8px;
            margin: 5px;
            flex: 1;
            text-align: center;
            min-width: 120px;
        }
        
        ul {
            margin: 15px 0;
            padding-left: 25px;
        }
        
        li {
            margin: 8px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üß† LSTM Sentiment Analysis - Complete Explanation</h1>
        
        <div class="concept-box">
            <h2>ü§î What is Sentiment Analysis?</h2>
            <p><strong>Sentiment Analysis</strong> is like teaching a computer to understand emotions in text - whether someone is happy üòä, sad üò¢, or neutral üòê about something.</p>
            
            <div class="analogy">
                <strong>üé≠ Think of it like this:</strong><br>
                Imagine you're reading movie reviews. You can quickly tell if someone loved the movie ("Amazing! Best film ever!") or hated it ("Terrible waste of time"). 
                Our goal is to teach a computer to do the same thing automatically for thousands of reviews.
            </div>
        </div>

        <div class="concept-box">
            <h2>üßÆ What is LSTM?</h2>
            <p><strong>LSTM (Long Short-Term Memory)</strong> is a special type of artificial brain that's really good at understanding sequences - like words in a sentence.</p>
            
            <div class="analogy">
                <strong>üß† Think of it like this:</strong><br>
                When you read "The movie was really..." your brain remembers the beginning of the sentence and uses it to understand what comes next. 
                LSTM does the same - it "remembers" earlier words to understand the whole sentence better.
            </div>
            
            <div class="lstm-visual">
                <h3>üîÑ How LSTM Processes a Sentence</h3>
                <div class="data-flow">
                    <div class="data-box">This</div>
                    <div class="data-box">movie</div>
                    <div class="data-box">is</div>
                    <div class="data-box">amazing</div>
                </div>
                <div class="arrow">‚¨áÔ∏è</div>
                <div style="margin: 20px 0;">
                    <div class="neural-node">üìù</div>
                    <div class="neural-node">üß†</div>
                    <div class="neural-node">üí≠</div>
                    <div class="neural-node">‚ù§Ô∏è</div>
                </div>
                <div class="arrow">‚¨áÔ∏è</div>
                <div class="data-box" style="background: #38a169;">POSITIVE SENTIMENT üòä</div>
            </div>
        </div>

        <h2>üìã Let's Break Down the Code Step by Step</h2>

        <div class="step">
            <h3>Import Libraries (The Tools We Need)</h3>
            <div class="code-section">
                <div class="code-title">Importing Libraries</div>
import os                    # For file operations
import numpy as np           # For number crunching
import pandas as pd          # For handling data tables
import pickle               # For saving our trained components
import tensorflow as tf     # The AI/machine learning framework
from sklearn.model_selection import train_test_split  # Split data for training/testing
            </div>
            <div class="info">
                <strong>What's happening:</strong> We're gathering all our tools, like getting ingredients before cooking. Each library has a specific job - TensorFlow builds the AI brain, NumPy handles math, etc.
            </div>
        </div>

        <div class="step">
            <h3>Create Sample Data (Teaching Examples)</h3>
            <div class="code-section">
                <div class="code-title">Creating Training Data</div>
def create_sample_dataset(n_samples=2000):
    positive_texts = [
        "I love this product! It's amazing",
        "Fantastic quality! Highly recommend",
        # ... more positive examples
    ]
    
    negative_texts = [
        "Terrible quality! Complete waste of money",
        "Worst product ever. Don't buy this",
        # ... more negative examples
    ]
    
    neutral_texts = [
        "It's okay, nothing special but decent",
        "Average product for the price",
        # ... more neutral examples
    ]
            </div>
            <div class="analogy">
                <strong>üéì Think of it like teaching a child:</strong><br>
                To teach a kid what "happy," "sad," and "okay" mean, you show them examples:
                <ul>
                    <li>"I got ice cream!" = Happy üòä</li>
                    <li>"I dropped my ice cream!" = Sad üò¢</li>
                    <li>"The ice cream was okay" = Neutral üòê</li>
                </ul>
                Our code creates thousands of these examples for the computer to learn from.
            </div>
        </div>

        <div class="step">
            <h3>Clean the Text (Make It Computer-Friendly)</h3>
            <div class="code-section">
                <div class="code-title">Text Cleaning Function</div>
def clean_text(text):
    text = text.lower()                    # "HELLO" ‚Üí "hello"
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove punctuation
    text = ' '.join(text.split())          # Remove extra spaces
    # Remove common words like "the", "is", "and"
    return text
            </div>
            <div class="info">
                <strong>Why do this?</strong> Computers are picky! "Hello", "HELLO", and "hello!" look different to them, but mean the same to us. 
                Cleaning makes everything consistent so the computer can focus on the important words.
            </div>
            
            <div class="flow-diagram">
                <strong>Text Cleaning Process:</strong><br><br>
                "I LOVE This Product!!!" <br>
                <div class="arrow">‚¨áÔ∏è (lowercase)</div>
                "i love this product!!!" <br>
                <div class="arrow">‚¨áÔ∏è (remove punctuation)</div>
                "i love this product" <br>
                <div class="arrow">‚¨áÔ∏è (remove common words)</div>
                "love product"
            </div>
        </div>

        <div class="step">
            <h3>Convert Words to Numbers (Computer Translation)</h3>
            <div class="code-section">
                <div class="code-title">Tokenization Process</div>
tokenizer = Tokenizer(num_words=5000)  # Learn 5000 most common words
tokenizer.fit_on_texts(texts)          # Study all our text examples

# Convert words to numbers
sequences = tokenizer.texts_to_sequences(["I love this"])
# Result: [45, 12, 78] (each number represents a word)
            </div>
            <div class="concept-box">
                <strong>üî¢ Why numbers?</strong><br>
                Computers only understand numbers, not words. So we create a dictionary:
                <ul>
                    <li>"love" = 12</li>
                    <li>"hate" = 45</li>
                    <li>"good" = 78</li>
                    <li>"bad" = 134</li>
                </ul>
                Now "I love this" becomes [1, 12, 3] - much easier for the computer!
            </div>
        </div>

        <div class="step">
            <h3>Make All Sentences the Same Length (Padding)</h3>
            <div class="code-section">
                <div class="code-title">Sequence Padding</div>
# Before padding (different lengths):
sentences = [
    [12, 45],           # "love product" (2 words)
    [12, 45, 78, 90],   # "love great amazing product" (4 words)
    [34]                # "good" (1 word)
]

# After padding (all length 4):
padded = [
    [12, 45, 0, 0],     # Added zeros to make length 4
    [12, 45, 78, 90],   # Already length 4
    [34, 0, 0, 0]       # Added zeros to make length 4
]
            </div>
            <div class="info">
                <strong>Why same length?</strong> LSTM needs all inputs to be the same size, like having all students sit in rows of the same length. 
                We add zeros (empty seats) to make shorter sentences match longer ones.
            </div>
        </div>

        <div class="step">
            <h3>Build the LSTM Brain (Neural Network Architecture)</h3>
            <div class="code-section">
                <div class="code-title">LSTM Model Creation</div>
model = Sequential([
    # 1. Word Embedding: Convert numbers to rich representations
    Embedding(vocab_size, 128, input_length=max_len),
    
    # 2. Bidirectional LSTM: Read sentence forwards AND backwards
    Bidirectional(LSTM(128, return_sequences=True, dropout=0.3)),
    
    # 3. Another LSTM layer: Deeper understanding
    Bidirectional(LSTM(64, dropout=0.3)),
    
    # 4. Dense layer: Final thinking
    Dense(64, activation='relu'),
    
    # 5. Output layer: Make the final decision
    Dense(3, activation='softmax')  # 3 = negative, neutral, positive
])
            </div>
            
            <div class="lstm-visual">
                <h3>üèóÔ∏è LSTM Architecture Breakdown</h3>
                
                <div style="margin: 20px 0;">
                    <div class="data-box" style="background: #9f7aea;">INPUT: "This movie is great"</div>
                </div>
                
                <div class="arrow">‚¨áÔ∏è</div>
                <div style="margin: 15px 0;">
                    <strong>üî§ Embedding Layer:</strong> Converts each word to a rich 128-number description
                </div>
                
                <div class="arrow">‚¨áÔ∏è</div>
                <div style="margin: 15px 0;">
                    <strong>üîÑ Bidirectional LSTM 1:</strong> Reads forwards "This‚Üímovie‚Üíis‚Üígreat" AND backwards "great‚Üíis‚Üímovie‚ÜíThis"
                </div>
                
                <div class="arrow">‚¨áÔ∏è</div>
                <div style="margin: 15px 0;">
                    <strong>üîÑ Bidirectional LSTM 2:</strong> Deeper analysis of the patterns found
                </div>
                
                <div class="arrow">‚¨áÔ∏è</div>
                <div style="margin: 15px 0;">
                    <strong>üß† Dense Layer:</strong> Final reasoning about what the sentence means
                </div>
                
                <div class="arrow">‚¨áÔ∏è</div>
                <div style="margin: 15px 0;">
                    <strong>üìä Output:</strong> [0.1, 0.1, 0.8] = 80% positive, 10% neutral, 10% negative
                </div>
            </div>
            
            <div class="analogy">
                <strong>üïµÔ∏è Think of the LSTM like a detective:</strong><br>
                <ul>
                    <li><strong>Embedding:</strong> Getting detailed info about each clue (word)</li>
                    <li><strong>Bidirectional reading:</strong> Reading the story forwards AND backwards to catch details</li>
                    <li><strong>Multiple layers:</strong> Looking deeper, finding hidden patterns</li>
                    <li><strong>Final decision:</strong> "Based on all evidence, this person is happy/sad/neutral"</li>
                </ul>
            </div>
        </div>

        <div class="step">
            <h3>Train the Model (Teaching Time!)</h3>
            <div class="code-section">
                <div class="code-title">Training Process</div>
# Split data: 70% for learning, 15% for checking, 15% for final test
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)

# Teach the model
history = model.fit(
    X_train, y_train,           # Training examples
    validation_data=(X_val, y_val),  # Check progress on unseen data
    epochs=15,                  # Go through all examples 15 times
    batch_size=32              # Process 32 examples at a time
)
            </div>
            <div class="concept-box">
                <strong>üéì Training is like school:</strong>
                <ul>
                    <li><strong>Training data:</strong> Homework problems with answers</li>
                    <li><strong>Validation data:</strong> Pop quizzes to check understanding</li>
                    <li><strong>Test data:</strong> Final exam (unused until the very end)</li>
                    <li><strong>Epochs:</strong> Like school years - going through all material multiple times</li>
                    <li><strong>Batch size:</strong> Like studying 32 problems at once before taking a break</li>
                </ul>
            </div>
        </div>

        <div class="step">
            <h3>Save the Trained Model (Preserve the Learning)</h3>
            <div class="code-section">
                <div class="code-title">Saving Model and Tokenizer</div>
# Save the trained brain
model.save('models/sentiment_model.h5')

# Save the word dictionary
with open('models/tokenizer.pickle', 'wb') as f:
    pickle.dump(tokenizer, f)
            </div>
            <div class="success">
                <strong>üíæ Why save?</strong> Training takes time and computational power. Saving lets us use the trained model later without retraining - like saving your progress in a video game!
            </div>
        </div>

        <div class="step">
            <h3>Use the Model (Make Predictions)</h3>
            <div class="code-section">
                <div class="code-title">Making Predictions</div>
def predict_sentiment(text):
    # 1. Clean the new text
    cleaned = clean_text(text)
    
    # 2. Convert to numbers using our saved dictionary
    sequence = tokenizer.texts_to_sequences([cleaned])
    
    # 3. Pad to correct length
    padded = pad_sequences(sequence, maxlen=100)
    
    # 4. Ask our trained model for prediction
    prediction = model.predict(padded)
    
    # 5. Convert numbers back to human language
    # [0.1, 0.2, 0.7] becomes "70% positive"
    sentiments = ['negative', 'neutral', 'positive']
    predicted_class = np.argmax(prediction)
    confidence = prediction[0][predicted_class]
    
    return sentiments[predicted_class], confidence
            </div>
        </div>

        <div class="concept-box">
            <h2>üîÑ The Complete Flow</h2>
            <div class="flow-diagram">
                <strong>From Text to Prediction:</strong><br><br>
                
                <div class="data-box" style="background: #e53e3e;">"I hate this movie!"</div>
                <div class="arrow">‚¨áÔ∏è Clean Text</div>
                <div class="data-box" style="background: #dd6b20;">"hate movie"</div>
                <div class="arrow">‚¨áÔ∏è Convert to Numbers</div>
                <div class="data-box" style="background: #d69e2e;">[45, 123]</div>
                <div class="arrow">‚¨áÔ∏è Pad Sequence</div>
                <div class="data-box" style="background: #38a169;">[45, 123, 0, 0, 0...]</div>
                <div class="arrow">‚¨áÔ∏è LSTM Processing</div>
                <div class="data-box" style="background: #3182ce;">[0.8, 0.1, 0.1]</div>
                <div class="arrow">‚¨áÔ∏è Interpret Result</div>
                <div class="data-box" style="background: #805ad5;">"80% NEGATIVE"</div>
            </div>
        </div>

        <div class="warning">
            <h3>üéØ Key Points to Remember:</h3>
            <ul>
                <li><strong>LSTM = Memory:</strong> Unlike simple models, LSTM remembers context from earlier words</li>
                <li><strong>Bidirectional = Smart:</strong> Reading both ways catches more patterns</li>
                <li><strong>Training = Learning:</strong> The model learns by seeing thousands of examples</li>
                <li><strong>Numbers = Computer Language:</strong> Everything must be converted to numbers</li>
                <li><strong>Padding = Consistency:</strong> All inputs must be the same size</li>
            </ul>
        </div>

        <div class="success">
            <h3>üéâ Congratulations!</h3>
            <p>You now understand how LSTM sentiment analysis works! The model learns patterns from examples, remembers context using its "memory," and can predict emotions in new text it's never seen before.</p>
            
            <p><strong>Next:</strong> Run the training script to create your own sentiment analysis model, then launch the web app to see it in action!</p>
        </div>
    </div>
</body>
</html>